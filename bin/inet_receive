#!/usr/bin/env python3
"""
Receive files using a robust, multi-threaded producer-consumer architecture.
"""
import argparse
import hashlib
import json
import logging
import os
import socket
import sys
import traceback
import shutil
import struct
#import threading
import queue
import time
# Dành cho kiến trúc song song thực!
import multiprocessing as mp
import sqlite3
from logging import handlers

# ==============================================================================
# 1. CẤU HÌNH VÀ BIẾN TOÀN CỤC
# ==============================================================================

# Cấu hình logging: Chỉ dùng StreamHandler, systemd sẽ tự động thu thập log
DIODE_LOGGER = logging.getLogger('INET_RX_PROXY')
DIODE_LOGGER.setLevel(logging.INFO)
STDERR_FORMATTER = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s: %(message)s')
STDERR_HANDLER = logging.StreamHandler(sys.stderr)
STDERR_HANDLER.setFormatter(STDERR_FORMATTER)
DIODE_LOGGER.addHandler(STDERR_HANDLER)
DB_PATH = '/var/log/inet_receive_logs.db'
# Hàng đợi (Queue) thread-safe để giao tiếp giữa 2 luồng
DATA_QUEUE = mp.Queue(maxsize=200000)  # Tăng kích thước để có bộ đệm lớn hơn

# Các hằng số của giao thức
PKG_TYPE_START = 0
PKG_TYPE_DATA = 1
PKG_TYPE_END = 2
HEADER_FORMAT = '!B16sI'
HEADER_SIZE = struct.calcsize(HEADER_FORMAT)

# ==============================================================================
# 2. CÁC LỚP VÀ HÀM TIỆN ÍCH
# ==============================================================================

class ReceiveState:
    """Lớp dữ liệu đơn giản để theo dõi trạng thái của file đang nhận."""
    def __init__(self, file_path: str, file_md5: str, file_size: int, output_dir: str):
        self.file_path = file_path
        self.file_md5 = file_md5
        self.file_size = file_size
        self.bytes_transferred = 0
        self.known_chunks = set()
        self.full_path = os.path.join(output_dir, self.file_path)
        self.file_handle = None

def calculate_file_md5(filepath: str) -> str:
    """Tính toán mã hash MD5 của một file."""
    md5_hash = hashlib.md5()
    try:
        with open(filepath, "rb") as f:
            for byte_block in iter(lambda: f.read(8192), b""):
                md5_hash.update(byte_block)
        return md5_hash.hexdigest()
    except FileNotFoundError:
        DIODE_LOGGER.error(f"File not found for MD5 calculation: {filepath}")
        return None
        
def init_db():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS transfer_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            filename TEXT NOT NULL,
            filesize INTEGER,
            status TEXT
        )
    ''')
    conn.commit()
    conn.close()
# ==============================================================================
# 3. LUỒNG NHẬN MẠNG (PRODUCER)
# ==============================================================================

class NetworkThread(mp.Process):
    """Tiến trình này chỉ nhận gói tin từ mạng và đưa vào hàng đợi."""
    def __init__(self, sock, data_queue):
        super().__init__()
        self.sock = sock
        self.data_queue = data_queue
        self.running = mp.Value('b', True) # Dùng biến chia sẻ để dừng

    def run(self):
        DIODE_LOGGER.info("NetworkProcess started. Listening for packets...")
        packets_dropped = 0
        while self.running.value:
            try:
                data, _ = self.sock.recvfrom(16384)
                if data:
                    try:
                        # Dùng put_nowait để không bị block, tránh treo luồng mạng
                        self.data_queue.put_nowait(data)
                    except queue.Full:
                        packets_dropped += 1
                        if packets_dropped % 1000 == 1:
                            DIODE_LOGGER.warning(f"DATA_QUEUE is full. Dropping packets... (Total dropped: {packets_dropped})")
            except socket.timeout:
                continue
            except Exception as e:
                DIODE_LOGGER.error(f"NetworkProcess error: {e}")

    def stop(self):
        self.running = False

# ==============================================================================
# 4. LUỒNG GHI ĐĨA (CONSUMER)
# ==============================================================================

class DiskWriterThread(mp.Process):
    """Luồng này lấy dữ liệu từ hàng đợi, xử lý và ghi ra đĩa."""
    def __init__(self, data_queue, output_dir: str, server_dir: str):
        super().__init__()
        self.data_queue = data_queue
        self.output_dir = output_dir
        self.server_dir = server_dir
        self.running = mp.Value('b', True)
        self.current_transfer = None  # Quản lý trạng thái bên trong luồng, không dùng biến toàn cục

    def run(self):
        DIODE_LOGGER.info("DiskWriterProcess started. Waiting for data...")
        while self.running:
            try:
                data = self.data_queue.get(timeout=1)
                self._process_packet(data)
            except queue.Empty:
                continue
            except Exception as e:
                DIODE_LOGGER.error(f"DiskWriterProcess error: {e}")
                traceback.print_exc()
                self._reset_transfer()

    def _process_packet(self, data: bytes):
        """Phân loại và xử lý gói tin."""
        if not data: return

        if data[0] == 123: # Gói JSON
            try:
                packet = json.loads(data.decode())
                pkt_type = packet.get("t")
                if pkt_type == PKG_TYPE_START:
                    self._handle_start(packet)
                elif pkt_type == PKG_TYPE_END and self.current_transfer:
                    # Chỉ xử lý END nếu hash khớp với file đang nhận
                    if packet.get('h') == self.current_transfer.file_md5:
                        self._handle_end(packet)
            except (json.JSONDecodeError, KeyError):
                DIODE_LOGGER.warning("Received malformed JSON. Ignoring.")
        else: # Gói Binary
            if self.current_transfer:
                self._handle_data(data)

    def _handle_start(self, packet: dict):
        """Xử lý khi bắt đầu một file mới."""
        if self.current_transfer is not None:
            #if self.current_transfer.file_md5 == packet.get('h'):
            #    return
            DIODE_LOGGER.warning(f"Received new START while transfer for {self.current_transfer.file_path} is in progress. Aborting old one.")
            self._reset_transfer()

        DIODE_LOGGER.info(f"Receiving file {packet['p']}")
        self.current_transfer = ReceiveState(
            file_path=packet['p'],
            file_md5=packet.get('h'), # Giả định 'h' là md5 của file
            file_size=packet['s'],
            output_dir=self.output_dir
        )
        
        os.makedirs(os.path.dirname(self.current_transfer.full_path), exist_ok=True)
        try:
            if os.path.exists(self.current_transfer.full_path):
                os.remove(self.current_transfer.full_path)
            self.current_transfer.file_handle = open(self.current_transfer.full_path, "ab")
        except Exception as e:
            DIODE_LOGGER.error(f"Failed to open file for writing: {e}")
            self._reset_transfer()

    def _handle_data(self, data: bytes):
        """Xử lý một chunk dữ liệu nhị phân."""
        try:
            header = data[:HEADER_SIZE]
            payload_data = data[HEADER_SIZE:]
            _, path_hash_bytes, count = struct.unpack(HEADER_FORMAT, header)
            #if path_hash_bytes.hex() == self.current_transfer.file_md5:
            if self.current_transfer.file_handle:
                self.current_transfer.file_handle.write(payload_data)
                self.current_transfer.known_chunks.add(count)
                self.current_transfer.bytes_transferred += len(payload_data)
            #else:
            #    DIODE_LOGGER.warning("Data packet with mismatched MD5 received. Ignoring.")
        except struct.error:
            DIODE_LOGGER.warning("Malformed binary packet received. Ignoring.")

    def _handle_end(self, packet: dict):
        """Xử lý khi kết thúc một file."""
        #DIODE_LOGGER.info(f"Finished receiving {self.current_transfer.file_path}. Validating...")
        
        if self._is_file_valid(packet):
            DIODE_LOGGER.info(f"File '{self.current_transfer.file_path}' is valid. Moving to outgoing queue.")
            try:
                dest_path = os.path.join(self.server_dir, self.current_transfer.file_path)
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                shutil.move(self.current_transfer.full_path, dest_path)
                self._log_transfer_to_db(self.current_transfer.file_path, self.current_transfer.file_size, "SUCCESS")
            except Exception as e:
                DIODE_LOGGER.error(f"Could not move file to outgoing queue: {e}")
        else:
            DIODE_LOGGER.error(f"File '{self.current_transfer.file_path}' is invalid. Deleting.")
            self._log_transfer_to_db(self.current_transfer.file_path, self.current_transfer.file_size, "FAILED")
            try:
                os.remove(self.current_transfer.full_path)
            except OSError: pass
        
        self._reset_transfer()

    def _is_file_valid(self, packet: dict) -> bool:
        """Kiểm tra tính toàn vẹn của file đã nhận."""
        state = self.current_transfer
        if not os.path.exists(state.full_path):
            DIODE_LOGGER.error("Validation failed: File does not exist.")
            return False

        if state.file_handle and not state.file_handle.closed:
            state.file_handle.close()

        success = True
        if len(state.known_chunks) != packet.get('c', -1):
            DIODE_LOGGER.error(f"Missing chunks. Expected {packet.get('c', -1)} but received {len(state.known_chunks)}.")
            success = False
        
        if state.file_size != os.path.getsize(state.full_path):
            DIODE_LOGGER.error(f"Filesize mismatch. Expected {state.file_size} but got {os.path.getsize(state.full_path)}.")
            success = False
            
        if state.file_md5:
            calculated_md5 = calculate_file_md5(state.full_path)
            if calculated_md5 != state.file_md5:
                DIODE_LOGGER.error(f"MD5 mismatch. Expected {state.file_md5} but got {calculated_md5}.")
                success = False
        
        return success

    def _reset_transfer(self):
        """Dọn dẹp trạng thái phiên truyền hiện tại."""
        if self.current_transfer and self.current_transfer.file_handle and not self.current_transfer.file_handle.closed:
            self.current_transfer.file_handle.close()
        self.current_transfer = None

    def stop(self):
        self.running = False

    def _log_transfer_to_db(self, filename, filesize, status):
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            cursor.execute("INSERT INTO transfer_logs (filename, filesize, status) VALUES (?, ?, ?)",
                        (filename, filesize, status))
            conn.commit()
            conn.close()
        except Exception as e:
            DIODE_LOGGER.error(f"Failed to log transfer to DB: {e}")

# ==============================================================================
# 5. HÀM MAIN ĐỂ KHỞI TẠO VÀ CHẠY
# ==============================================================================

def main():
    parser = argparse.ArgumentParser(description='Diode Receive Daemon')
    parser.add_argument('--bind-subnet', type=str, default="10.10.2.3")
    parser.add_argument('--bind-port', type=int, default=9009)
    parser.add_argument('--directory', type=str, required=True, help='Temporary directory to receive files')
    parser.add_argument('--server-directory', type=str, required=True, help='Directory to move completed files')
    args = parser.parse_args()

    # Tạo socket
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    sock.bind((args.bind_subnet, args.bind_port))
    sock.settimeout(1.0) 
    # Khởi tạo DB
    init_db()
    # DÙNG MULTIPROCESSING QUEUE
    data_queue = mp.Queue(maxsize=200000)

    # Khởi tạo và chạy các luồng
    network_process = NetworkThread(sock, data_queue)
    disk_process = DiskWriterThread(data_queue, args.directory, args.server_directory)
    
    processes = [network_process, disk_process]
    try:
        for p in processes:
            p.start()
        for p in processes:
            p.join() # Chờ các tiến trình kết thúc
    except KeyboardInterrupt:
        DIODE_LOGGER.info("Shutdown signal received. Stopping processes.")
        for p in processes:
            p.stop()
            p.terminate() # Buộc dừng nếu cần
            p.join()

if __name__ == "__main__":
    main()